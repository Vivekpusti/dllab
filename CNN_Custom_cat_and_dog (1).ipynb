{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09b88e0",
   "metadata": {},
   "source": [
    "### import all necessary libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a2c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7854065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e07aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407d6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"D:\\Downloads\\Cat_and_Dog\\dataset\\training_set\"\n",
    "test_dir = r\"D:\\Downloads\\Cat_and_Dog\\dataset\\test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3f922f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_dir\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "train_dir[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c633fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62387dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size=(124, 124)\n",
    "batch_size = 30\n",
    "no_epochs = 50\n",
    "steps_per_epochs = no_epochs // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e0f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(124, 124),batch_size=batch_size,class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(124, 124),batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80206503",
   "metadata": {},
   "source": [
    "### Build a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8141752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 122, 122, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 61, 61, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 61, 61, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 59, 59, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 29, 29, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 53824)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 53824)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 53825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,217\n",
      "Trainable params: 73,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(124,124,3)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e292436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2257d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7111 - accuracy: 0.5333 - val_loss: 0.6099 - val_accuracy: 0.7000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3138 - accuracy: 0.3667 - val_loss: 0.6989 - val_accuracy: 0.4667\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8014 - accuracy: 0.4000 - val_loss: 0.7185 - val_accuracy: 0.4667\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.8870 - accuracy: 0.4333 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6810 - accuracy: 0.6000 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7035 - accuracy: 0.4667 - val_loss: 0.6871 - val_accuracy: 0.5333\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7220 - accuracy: 0.3333 - val_loss: 0.6990 - val_accuracy: 0.4333\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7271 - accuracy: 0.4333 - val_loss: 0.6895 - val_accuracy: 0.5333\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7568 - accuracy: 0.3333 - val_loss: 0.6898 - val_accuracy: 0.5333\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7241 - accuracy: 0.5667 - val_loss: 0.6900 - val_accuracy: 0.5333\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6983 - accuracy: 0.5000 - val_loss: 0.6830 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6635 - accuracy: 0.7000 - val_loss: 0.6904 - val_accuracy: 0.5667\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6887 - accuracy: 0.5333 - val_loss: 0.6806 - val_accuracy: 0.6333\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6937 - accuracy: 0.5333 - val_loss: 0.7004 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6973 - accuracy: 0.5333 - val_loss: 0.6858 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7053 - accuracy: 0.5333 - val_loss: 0.6952 - val_accuracy: 0.4000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6770 - accuracy: 0.5667 - val_loss: 0.6914 - val_accuracy: 0.5333\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6992 - accuracy: 0.5000 - val_loss: 0.6860 - val_accuracy: 0.6333\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6673 - accuracy: 0.6333 - val_loss: 0.6880 - val_accuracy: 0.6000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6858 - accuracy: 0.5333 - val_loss: 0.6862 - val_accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7004 - accuracy: 0.4667 - val_loss: 0.6947 - val_accuracy: 0.4333\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6771 - accuracy: 0.6000 - val_loss: 0.6863 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6864 - accuracy: 0.4667 - val_loss: 0.6849 - val_accuracy: 0.6333\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7218 - accuracy: 0.4000 - val_loss: 0.6905 - val_accuracy: 0.5333\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7024 - accuracy: 0.4333 - val_loss: 0.6957 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7048 - accuracy: 0.4000 - val_loss: 0.6935 - val_accuracy: 0.4333\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6968 - accuracy: 0.4000 - val_loss: 0.6934 - val_accuracy: 0.5333\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6934 - accuracy: 0.4667 - val_loss: 0.6913 - val_accuracy: 0.6000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6882 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.4667\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6863 - accuracy: 0.4667 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.4667\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6781 - accuracy: 0.6000 - val_loss: 0.6947 - val_accuracy: 0.4667\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6757 - accuracy: 0.5667 - val_loss: 0.6873 - val_accuracy: 0.6333\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7086 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.5333\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7084 - accuracy: 0.4333 - val_loss: 0.6806 - val_accuracy: 0.6000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6861 - accuracy: 0.5667 - val_loss: 0.6899 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7583 - accuracy: 0.3667 - val_loss: 0.6898 - val_accuracy: 0.5333\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6789 - accuracy: 0.6667 - val_loss: 0.6914 - val_accuracy: 0.6333\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6999 - accuracy: 0.5333 - val_loss: 0.6888 - val_accuracy: 0.6333\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6835 - accuracy: 0.5333 - val_loss: 0.6880 - val_accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6460 - accuracy: 0.7333 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6978 - accuracy: 0.5000 - val_loss: 0.6737 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6739 - accuracy: 0.5000 - val_loss: 0.6956 - val_accuracy: 0.4333\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7055 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.4333\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6998 - accuracy: 0.5333 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7314 - accuracy: 0.4667 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6736 - accuracy: 0.5333 - val_loss: 0.6901 - val_accuracy: 0.4333\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6289 - accuracy: 0.6667 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6975 - accuracy: 0.5000 - val_loss: 0.6991 - val_accuracy: 0.3667\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7386 - accuracy: 0.4667 - val_loss: 0.6788 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2719dc5eb20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,steps_per_epoch=steps_per_epochs,epochs=no_epochs,validation_data=test_generator,\n",
    "        validation_steps=30//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99890f93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCat_and_Dog\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtraining_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcats\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat.4001.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload_img(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCat_and_Dog\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest_set\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcats\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat.4001.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# this is a PIL image\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mimg_to_array\u001b[49m(img)  \u001b[38;5;66;03m# this is a Numpy array with shape (3, 150, 150)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# this is a Numpy array with shape (1, 3, 150, 150)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# the .flow() command below generates batches of randomly transformed images\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# and saves the results to the `preview/` directory\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "path = r\"D\\Downloads\\Cat_and_Dog\\dataset\\training_set\\cats\\cat.4001.jpg\"\n",
    "img = tf.keras.preprocessing.image.load_img(r\"D:\\Downloads\\Cat_and_Dog\\dataset\\test_set\\cats\\cat.4001.jpg\")  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b179f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e264ba58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
